## Brazilian E-Commerce Data Pipeline with Azure Databricks
üìå Overview

This project implements a data ingestion and transformation pipeline for the Brazilian E-Commerce Public Dataset using Azure Databricks and PySpark.
It extracts raw data from Azure Data Lake Storage (ADLS), transforms it using Spark, and stores the processed data for further analysis.

The pipeline is designed for scalability, security, and automation, making it suitable for real-world big data processing scenarios.

‚öôÔ∏è Features

1. Raw Data Ingestion from Azure Data Lake Storage Gen2

2. Secure Authentication with Azure OAuth 2.0

3. Data Cleaning & Transformation using PySpark

4. Schema Definition & Validation to ensure data quality

5. Processed Data Storage in ADLS for downstream analytics

6. Databricks Notebooks for modular, maintainable code

7. Integration with GitHub for version control

üõ†Ô∏è Technologies Used

1. Azure Databricks

2. Apache Spark (v3.5.0)

3. Python (PySpark)

4. Azure Data Lake Storage Gen2

5. Azure Active Directory (AAD) for OAuth authentication

6. GitHub for source control
